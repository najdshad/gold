{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9641/4249613357.py:5: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
      "  df = pd.read_csv(\n",
      "/tmp/ipykernel_9641/4249613357.py:5: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete with spread-adjusted conditions.\n"
     ]
    }
   ],
   "source": [
    "def transform_and_calculate(file_path, stop_distance=2, rr_ratio=3, lookahead=30):\n",
    "    # 1. Data transformation\n",
    "    def load_and_transform(file_path):\n",
    "        # Load CSV with proper datetime handling\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            delimiter='\\t',\n",
    "            parse_dates={'datetime': ['<DATE>', '<TIME>']},\n",
    "            date_parser=lambda x: pd.to_datetime(x, format='%Y.%m.%d %H:%M:%S'),\n",
    "            usecols=['<DATE>', '<TIME>', '<OPEN>', '<HIGH>', '<LOW>', '<CLOSE>', '<TICKVOL>', '<SPREAD>']\n",
    "        )\n",
    "        \n",
    "        # Clean column names\n",
    "        df.columns = df.columns.str.strip('<>').str.lower()\n",
    "        \n",
    "        # Column renaming and reorganization\n",
    "        df = df.rename(columns={'tickvol': 'vol'})\n",
    "        df = df[['datetime', 'open', 'high', 'low', 'close', 'vol', 'spread']]\n",
    "        \n",
    "        return df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "    # 2. Spread-adjusted condition calculation\n",
    "    def calculate_condition_met(df, stop_distance, rr_ratio, lookahead):\n",
    "        # Initialize both condition columns\n",
    "        df['long_condition'] = False\n",
    "        df['short_condition'] = False\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            current = df.iloc[i]\n",
    "            future = df.iloc[i+1:i+lookahead+1]\n",
    "            \n",
    "            if future.empty:\n",
    "                break\n",
    "            \n",
    "            # Calculate entry prices with spread adjustment\n",
    "            long_entry = current['close'] + current['spread'] * 0.01\n",
    "            short_entry = current['close'] - current['spread'] * 0.01\n",
    "            \n",
    "            # Calculate price levels with spread\n",
    "            long_stop = long_entry - stop_distance\n",
    "            long_target = long_entry + (stop_distance * rr_ratio)\n",
    "            short_stop = short_entry + stop_distance\n",
    "            short_target = short_entry - (stop_distance * rr_ratio)\n",
    "            \n",
    "            # Track both scenarios\n",
    "            long_met, long_broken = False, False\n",
    "            short_met, short_broken = False, False\n",
    "            \n",
    "            for _, candle in future.iterrows():\n",
    "                # Check long condition\n",
    "                if not long_met and not long_broken:\n",
    "                    if candle['low'] <= long_stop:\n",
    "                        long_broken = True\n",
    "                    elif candle['high'] >= long_target:\n",
    "                        long_met = True\n",
    "                \n",
    "                # Check short condition\n",
    "                if not short_met and not short_broken:\n",
    "                    if candle['high'] >= short_stop:\n",
    "                        short_broken = True\n",
    "                    elif candle['low'] <= short_target:\n",
    "                        short_met = True\n",
    "                \n",
    "                # Early exit if both scenarios resolved\n",
    "                if (long_met or long_broken) and (short_met or short_broken):\n",
    "                    break\n",
    "            \n",
    "            # Set conditions independently\n",
    "            df.at[i, 'long_condition'] = long_met\n",
    "            df.at[i, 'short_condition'] = short_met\n",
    "        \n",
    "        return df\n",
    "\n",
    "    # Execute processing pipeline\n",
    "    df = load_and_transform(file_path)\n",
    "    df = calculate_condition_met(df, stop_distance, rr_ratio, lookahead)\n",
    "    return df\n",
    "\n",
    "# Usage example:\n",
    "csv_path = 'Data/MT5/XAUUSD_M15_202012070900_202502282345.csv'\n",
    "processed_data = transform_and_calculate(csv_path)\n",
    "processed_data.to_csv('processed.csv', index=False)\n",
    "print(\"Data processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
